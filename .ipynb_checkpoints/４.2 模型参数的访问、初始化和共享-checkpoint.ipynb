{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "net.parameters():a generator\n",
    "net.named_parameter():包含了名字，\n",
    "for name,param in named_parameters():\n",
    "这里面的param是一个<class 'torch.nn.parameter.Parameter'>对象，\n",
    "所以当在init中自己初始化这种参数对象时候，也会被添加到net.paramters中\n",
    "list(net[0].parameters())[0]:取第０层的ｗ参数\n",
    "param.data:取数据\n",
    "param.grad：取梯度\n",
    "共享参数就是，在容器中传入相同的两层\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(4,3),nn.ReLU(),nn.Linear(3,1))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1221],\n",
      "        [-0.1221]], grad_fn=<AddmmBackward>)\n",
      "tensor(-0.2442, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,4)\n",
    "print(net(x))\n",
    "print(net(x).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "print(type(net.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([3, 4])\n",
      "0.bias torch.Size([3])\n",
      "2.weight torch.Size([1, 3])\n",
      "2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name,param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([3, 4]) <class 'torch.nn.parameter.Parameter'>\n",
      "bias torch.Size([3]) <class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "for name,param in net[0].named_parameters():\n",
    "    print(name,param.size(),type(param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1052,  0.1292, -0.3931, -0.2488],\n",
      "        [-0.0331, -0.4442, -0.2251, -0.2343],\n",
      "        [ 0.0236,  0.4007, -0.1574, -0.2705]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1867, -0.2132, -0.2968], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.5094, 0.2146, 0.4552]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1221], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1052,  0.1292, -0.3931, -0.2488],\n",
      "        [-0.0331, -0.4442, -0.2251, -0.2343],\n",
      "        [ 0.0236,  0.4007, -0.1574, -0.2705]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1867, -0.2132, -0.2968], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)\n",
    "for param in net[0].parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight1 torch.Size([20, 20])\n"
     ]
    }
   ],
   "source": [
    "class mymodel(nn.Module):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(mymodel,self).__init__()\n",
    "        self.weight1 = nn.Parameter(torch.rand(20,20))\n",
    "        self.weight2 = torch.rand(20,20)\n",
    "    def foward(self,x):\n",
    "        pass\n",
    "n = mymodel()\n",
    "for name, param in n.named_parameters():\n",
    "    print(name,param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3892, -0.0748, -0.1027,  0.1574],\n",
      "        [-0.3803,  0.0503, -0.1482,  0.0424],\n",
      "        [-0.1011,  0.0782,  0.2001,  0.3051]])\n"
     ]
    }
   ],
   "source": [
    "weight_0 = list(net[0].parameters())[0]\n",
    "print(weight_0.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(weight_0.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=net(x)\n",
    "Y.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1961,  0.0059,  0.1780,  0.2327],\n",
      "        [-0.6763, -0.3610, -0.5222, -0.4619],\n",
      "        [-0.7704, -0.4112, -0.5948, -0.5261]])\n"
     ]
    }
   ],
   "source": [
    "print(weight_0.grad)#反向传播以后才会有梯度值！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor([[-0.0013, -0.0024, -0.0149,  0.0046],\n",
      "        [ 0.0144, -0.0036,  0.0034,  0.0116],\n",
      "        [ 0.0173,  0.0013, -0.0042, -0.0057]])\n",
      "0.bias tensor([0., 0., 0.])\n",
      "2.weight tensor([[-0.0127, -0.0007,  0.0093]])\n",
      "2.bias tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.normal_(param, mean=0,std=0.01)\n",
    "        print(name,param.data)\n",
    "    elif 'bias' in name:\n",
    "        init.constant_(param,val=0)\n",
    "        print(name,param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(tensor):\n",
    "    with torch.no_grad():\n",
    "        tensor.uniform_(-10,10)\n",
    "        #print('main:',tensor.uniform_(-10,10))\n",
    "        #print(tensor.abs()>5)\n",
    "        tensor*=(tensor.abs()>=5).float()\n",
    "        #print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor([[ 0.0000,  0.0000,  8.1440, -6.5662],\n",
      "        [-0.0000, -0.0000, -7.3206,  7.8549],\n",
      "        [ 5.4216,  7.4208,  7.9317,  7.3940]])\n",
      "2.weight tensor([[ 0.0000, -7.6710, -0.0000]])\n"
     ]
    }
   ],
   "source": [
    "for name,param in net.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init_weight(param)\n",
    "        print(name,param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.bias tensor([1., 1., 1.])\n",
      "2.bias tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "for name,param in net.named_parameters():\n",
    "    if 'bias' in name:\n",
    "        param.data+=1\n",
    "        print(name,param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=1, bias=False)\n",
      "  (1): Linear(in_features=1, out_features=1, bias=False)\n",
      ")\n",
      "0.weight tensor([[3.]])\n"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(1,1,bias=False)\n",
    "net = nn.Sequential(linear,linear)\n",
    "print(net)\n",
    "for name,param in net.named_parameters():\n",
    "    init.constant_(param,val=3)\n",
    "    print(name,param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(id(net[0])==id(net[1]))\n",
    "print(id(net[0].weight)==id(net[1].weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9., grad_fn=<SumBackward0>)\n",
      "tensor([[3.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(1,1)\n",
    "y = net(x).sum()\n",
    "print(y)\n",
    "y.backward()\n",
    "print(net[0].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
